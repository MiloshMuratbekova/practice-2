# Практическая работа №2
## Как запустить

Компиляция:
```bash
make
```

Запуск:
```bash
./sorting_openmp
```


## Ответы на контрольные вопросы

**1. В чём основные отличия алгоритмов сортировки пузырьком, выбором и вставкой?**

Сортировка пузырьком сравнивает соседние элементы и меняет их местами, если они в неправильном порядке. Большие элементы постепенно "всплывают" к концу массива.

Сортировка выбором на каждом шаге ищет минимальный элемент в неотсортированной части и ставит его в начало. Делает меньше обменов, чем пузырьком.

Сортировка вставкой берет элементы по одному и вставляет их в правильное место в отсортированной части массива. Эффективна на частично отсортированных данных.

Все три алгоритма имеют сложность O(n²), но работают по-разному.

**2. Почему параллельная реализация сортировки вставкой сложнее для выполнения с использованием OpenMP?**

Сортировка вставкой имеет последовательную зависимость - каждый новый элемент вставляется в уже отсортированную часть массива. То есть, чтобы вставить элемент, нужно знать результат обработки всех предыдущих элементов.

Из-за этого нельзя просто распараллелить основной цикл. Приходится использовать блочный подход: делим массив на части, каждую часть сортируем параллельно, а потом сливаем отсортированные части вместе.

**3. Какие директивы OpenMP были использованы для параллельной реализации алгоритмов?**

- `#pragma omp parallel for` - распараллеливает цикл, разделяя итерации между потоками
- `#pragma omp parallel` - создает параллельный регион с несколькими потоками
- `#pragma omp for nowait` - распределяет итерации цикла между потоками без ожидания
- `#pragma omp critical` - критическая секция, где одновременно может быть только один поток
- `shared(...)` - указывает, какие переменные общие для всех потоков

**4. Какие преимущества и недостатки параллельной реализации алгоритмов сортировки на CPU?**

Преимущества:
- Ускорение на больших массивах
- Использование всех ядер процессора
- С OpenMP легко добавить параллелизм в существующий код

Недостатки:
- Создание и синхронизация потоков требует времени
- На маленьких массивах параллельная версия может быть медленнее
- Не все алгоритмы хорошо параллелятся
- Сложнее отлаживать многопоточный код
- Закон Амдала ограничивает максимальное ускорение

**5. Как можно измерить производительность программы в C++?**

Есть несколько способов:

Библиотека chrono (используется в программе):
```cpp
auto start = high_resolution_clock::now();
// код
auto end = high_resolution_clock::now();
auto duration = duration_cast<milliseconds>(end - start);
```

Функция OpenMP:
```cpp
double start = omp_get_wtime();
// код
double end = omp_get_wtime();
double time = end - start;
```

Функция clock():
```cpp
clock_t start = clock();
// код
clock_t end = clock();
double time = (double)(end - start) / CLOCKS_PER_SEC;
```

Для параллельных программ лучше использовать chrono или omp_get_wtime(), потому что clock() суммирует время всех потоков.

**6. Как изменяется производительность сортировок при увеличении числа потоков?**

Сначала производительность растет - каждый новый поток ускоряет выполнение. Но только до определенного момента.

Когда количество потоков достигает числа ядер процессора, рост замедляется. А если потоков становится слишком много, производительность даже падает из-за накладных расходов на переключение между потоками и синхронизацию.

Также на масштабирование влияет размер массива (большие массивы лучше параллелятся) и сам алгоритм (некоторые плохо параллелятся из-за своей природы).

**7. В каких ситуациях параллельная сортировка может быть менее эффективной, чем последовательная?**

- На маленьких массивах - время на создание потоков больше, чем выигрыш от параллелизма
- Когда в алгоритме много последовательных участков кода
- При частой синхронизации потоков (критические секции, барьеры)
- На одноядерных процессорах - параллельное выполнение невозможно
- Когда работа неравномерно распределена между потоками
- На частично отсортированных данных для insertion sort
- Если параллельный алгоритм требует много дополнительной памяти
